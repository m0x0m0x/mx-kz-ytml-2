======== PART 18 OF 46  ========


------ FILE START ../../../kz-ytml-1/WX/tezt/gitml/gml1/runz.sh ------

#!/usr/bin/bash
# This bash srcript is for installing the KL docker image here
clear

# Colors
export RED='\033[0;31m'
export GREEN='\033[0;32m'
export YELLOW='\033[0;33m'
export BLUE='\033[0;34m'
export PURPLE='\033[0;35m'
export CYAN='\033[0;36m'
export WHITE='\033[0;37m'
export NC='\033[0m' # No Color

# Commands

hea1() {
    echo -e "${CYAN}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~${NC}"
    echo -e "${PURPLE}$1${NC}"
    echo -e "${CYAN}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~${NC}"
}

# Execution Zone
ru1() {
    hea1 "Execute UV "
    co1="uv run buty.py"
    echo -e "${GREEN} Executing... "
    echo -e " ${co1} ${NC}"
    eval "${co1}"
}

# Exection

ru1


------ FILE END ../../../kz-ytml-1/WX/tezt/gitml/gml1/runz.sh ------


------ FILE START ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/gm1.py ------

# ????????????????????????????????????????????????????????????
# gm1 - GithubMl Test1
# ????????????????????????????????????????????????????????????

# --- Imports Zone ---
import os

from dotenv import load_dotenv
from openai import OpenAI
from rich.pretty import pprint as ppr

from .utz import header1
from .wm import save_to_markdown

# -- Globsl Vars

# --- Load the envpussy --
load_dotenv("src/.pussy")
GH_T = os.getenv("GHT")

# --- Models List ---
model_ids = [
    "openai/gpt-4.1",
    "openai/gpt-4.1-mini",
    "openai/gpt-4.1-nano",
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "openai/o1",
    "openai/o1-mini",
    "openai/o1-preview",
    "openai/o3",
    "openai/o3-mini",
    "openai/o4-mini",
    "openai/text-embedding-3-large",
    "openai/text-embedding-3-small",
    "ai21-labs/ai21-jamba-1.5-large",
    "ai21-labs/ai21-jamba-1.5-mini",
    "cohere/cohere-command-a",
    "cohere/cohere-command-r",
    "cohere/cohere-command-r-08-2024",
    "cohere/cohere-command-r-plus",
    "cohere/cohere-command-r-plus-08-2024",
    "cohere/cohere-embed-v3-english",
    "cohere/cohere-embed-v3-multilingual",
    "core42/jais-30b-chat",
    "deepseek/deepseek-r1",
    "deepseek/deepseek-r1-0528",
    "deepseek/deepseek-v3-0324",
    "meta/llama-3.2-11b-vision-instruct",
    "meta/llama-3.2-90b-vision-instruct",
    "meta/llama-3.3-70b-instruct",
    "meta/llama-4-maverick-17b-128e-instruct-fp8",
    "meta/llama-4-scout-17b-16e-instruct",
    "meta/meta-llama-3.1-405b-instruct",
    "meta/meta-llama-3.1-70b-instruct",
    "meta/meta-llama-3.1-8b-instruct",
    "meta/meta-llama-3-70b-instruct",
    "meta/meta-llama-3-8b-instruct",
    "mistral-ai/codestral-2501",
    "mistral-ai/ministral-3b",
    "mistral-ai/mistral-large-2411",
    "mistral-ai/mistral-medium-2505",
    "mistral-ai/mistral-nemo",
    "mistral-ai/mistral-small-2503",
    "xai/grok-3",
    "xai/grok-3-mini",
    "microsoft/mai-ds-r1",
    "microsoft/phi-3.5-mini-instruct",
    "microsoft/phi-3.5-moe-instruct",
    "microsoft/phi-3.5-vision-instruct",
    "microsoft/phi-3-medium-128k-instruct",
    "microsoft/phi-3-medium-4k-instruct",
    "microsoft/phi-3-mini-128k-instruct",
    "microsoft/phi-3-mini-4k-instruct",
    "microsoft/phi-3-small-128k-instruct",
    "microsoft/phi-3-small-8k-instruct",
    "microsoft/phi-4",
    "microsoft/phi-4-mini-instruct",
    "microsoft/phi-4-mini-reasoning",
    "microsoft/phi-4-multimodal-instruct",
    "microsoft/phi-4-reasoning"
]


# -- Main Function Call --


def gm1_main():
    # print_env()  # Testing env access
    gm1_1()  # Run the official example test

# --- SubFunc---

# Test ENV Access


def print_env():
    header1("Brint ENV")
    ppr(f"GiGaand = {GH_T}")

# Official Example Test


def gm1_1():

    header1("Official Example Test")

    endpoint = "https://models.github.ai/inference"
    model = model_ids[58]

    client = OpenAI(
        base_url=endpoint,
        api_key=GH_T,
    )

    question = "What is smellpanty algoritm ?"

    response = client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant, who talks like in rhyming slang",
            },
            {
                "role": "user",
                "content": question,
            }
        ],
        temperature=1.0,
        top_p=1.0,
        model=model
    )

    # Print Console Output
    ppr(response.choices[0].message.content)

    # Save to Markdown
    save_to_markdown(
        response.choices[0].message.content,
        prefix="microsoft_phi-4-reasoning",
        directory="rez/",
        header_level=2,
        include_time_in_filename=True,
        metadata={
            "Model": model,
            "Endpoint": endpoint,
            "Question": question
        }
    )


------ FILE END ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/gm1.py ------


------ FILE START ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/gtm.py ------

# ????????????????????????????????????????????????????????????
# gtm.py - Get all github models
# ????????????????????????????????????????????????????????????

# --- Imports Zone ---
import json
import os

import httpx
from dotenv import load_dotenv
from rich.pretty import pprint as ppr

from .utz import header1
from .wm import save_to_markdown

# --- Load the envpussy --
load_dotenv("src/.pussy")
GH_T = os.getenv("GHT")


# -- Main Function Call --


def gm1_main():
    get_models_1()

# --- SubFunc---


def get_models_1():

    header1("fetch GitHUb Models")

    url = "https://models.github.ai/catalog/models"

    headers = {
        "Accept": "application/vnd.github+json",
        "Authorization": f"Bearer {GH_T}"
    }

    with httpx.Client() as client:
        response = client.get(url, headers=headers)

    # Print status code and response JSON
    print(f"Status Code: {response.status_code}")
    try:
        ppr(response.json())
        formatted_output = json.dumps(
            response.json(), indent=2, ensure_ascii=False)

        # Write to markdown file
        save_to_markdown(
            content=f"```json\n{formatted_output}\n```",
            prefix="gitmodelz",
            directory="rez/",
            header_level=2,
            include_time_in_filename=True,
        )

    except Exception:
        print("Failed to decode JSON")
        print(response.text)


------ FILE END ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/gtm.py ------


------ FILE START ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/utz.py ------

# Rich Prettifier Code
# ------------------------------------------------------
import logging

from rich.console import Console  # For console.print
from rich.logging import RichHandler
from rich.panel import Panel  # For Panel()
from rich.rule import Rule
from rich.traceback import install

console = Console()  # Standard code to access console
install(show_locals=True)

# Setting up rich logger with color
logging.basicConfig(
    level=logging.DEBUG,
    format="%(message)s",
    datefmt="[%X]",
    handlers=[RichHandler(rich_tracebacks=True, markup=True)],
)
log = logging.getLogger("rich")

# ------------------------------------------------------


def header1(text):
    panel = Panel.fit(
        f"""[green_yellow]{text}[/green_yellow]""",
        title="<:",
        subtitle=":>",
        style="Italic",
        border_style="magenta",
    )
    # Print the Panel
    console.print(panel)


def l_debug(text):
    log.debug(f"[green]{text}[/green]")


def l_info(text):
    log.info(f"[blue]{text}[/blue]")


def l_warning(text):
    log.warning(f"[yellow]{text}[/yellow]")


def l_error(text):
    log.error(f"[red]{text}[/red]")


def l_critical(text):
    log.critical(f"[white on red bold]{text}[/white on red bold]")


def tline():
    console.print(Rule(title="[green]Execution Section[/green]",
                  characters="┉", style="bold green"))


def eline():
    console.print(Rule(title="[green] END[/green]",
                  characters="┉", style="bold red"))


------ FILE END ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/utz.py ------


------ FILE START ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/wm.py ------

from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union


def save_to_markdown(
    content: Union[str, List, Dict, Any],
    prefix: str = "output",
    directory: str = ".",
    header_level: int = 1,
    include_time_in_filename: bool = True,
    metadata: Optional[Dict[str, str]] = None
) -> Path:
    """
    Saves content to a markdown file with date/time in filename and header.

    Args:
        content: Content to save (str, list, dict, or any object with __str__)
        prefix: Filename prefix before the date
        directory: Output directory
        header_level: Markdown header level (1-6)
        include_time_in_filename: Whether to include time in filename
        metadata: Optional dict of additional info to show at top (e.g., company name, address, phone)

    Returns:
        Path to the created markdown file

    Example Use:
        metadata = {
        "Company": "TechFusion Inc.",
        "Address": "123 Innovation Drive, Silicon Valley, CA 94043",
        "Phone": "+1 (555) 123-4567",
        "Email": "contact@techfusion.com",
        "Project": "Internal Security Audit",
    }

    save_to_markdown(
        ["Finding 1: XSS Vulnerability", "Finding 2: Weak Password Policy"],
        prefix="security_report",
        metadata=metadata
)
    """
    # Create directory if needed
    Path(directory).mkdir(parents=True, exist_ok=True)

    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    time_str = now.strftime("%H:%M:%S")
    datetime_str = f"{date_str} {time_str}"

    markdown_content = _convert_to_markdown(content, header_level)

    # Build metadata section
    header_section = ""
    if metadata:
        header_section = "\n".join(
            [f"- ##{key}: {value}" for key, value in metadata.items()])

    # Final content with header and metadata
    content_with_header = f"# Generated on {datetime_str}\n"
    if header_section:
        content_with_header += f"\n{header_section}\n"
    content_with_header += f"\n{markdown_content}"

    # Generate filename
    if include_time_in_filename:
        filename = f"{prefix}_{date_str}_{time_str.replace(':', '-')}.md"
    else:
        filename = f"{prefix}_{date_str}.md"

    filepath = Path(directory) / filename

    # Write to file
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content_with_header)

    return filepath


def _convert_to_markdown(content: Any, header_level: int = 1) -> str:
    """Helper function to convert different types to Markdown"""
    if isinstance(content, str):
        return content
    elif isinstance(content, (list, tuple, set)):
        return "\n".join(f"- {item}" for item in content)
    elif isinstance(content, dict):
        return "\n".join(f"- **{k}**: {v}" for k, v in content.items())
    else:
        header = "#" * header_level
        return f"{header} Content\n\n{str(content)}"


------ FILE END ../../../kz-ytml-1/WX/tezt/gitml/gml1/src/wm.py ------


======== END OF PART 18 OF 46  ========

This is only a part of the code. Please do not respond until I provide all parts (28 remaining).